#!/usr/bin/env python3
"""
Pipulate Master Release Orchestrator

A comprehensive release pipeline that handles:
1. Version synchronization across all files
2. ASCII art documentation synchronization  
3. AI-generated commit messages via local LLM
4. Trifecta derivative plugin rebuilding (when template changes detected)
5. Git operations and PyPI publishing

Usage:
  python helpers/release/publish.py --release -m "Custom message"
  python helpers/release/publish.py --release --force -m "Force republish"
  python helpers/release/publish.py --release --ai-commit  # Use AI for commit message
  python helpers/release/publish.py --release --skip-trifecta-rebuild  # Skip plugin rebuilding
"""
import argparse
import subprocess
import sys
import re
import json
import requests
from pathlib import Path

# Rich table imports for beautiful output
try:
    from rich.console import Console
    from rich.table import Table
    from rich.panel import Panel
    from rich.text import Text
    from rich import box
    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False
    print("üí° Install 'rich' for beautiful table output: pip install rich")

# --- Configuration ---
try:
    PIPULATE_ROOT = Path(__file__).parent.parent.parent.resolve()
except FileNotFoundError:
    print("Error: Could not resolve script path.")
    sys.exit(1)

INIT_PY_PATH = PIPULATE_ROOT / "__init__.py"
# Add Pipulate.com path configuration
PIPULATE_COM_ROOT = PIPULATE_ROOT.parent / "Pipulate.com"

def run_command(cmd, cwd=PIPULATE_ROOT, capture=False, check=True, shell=False):
    """Runs a command and handles errors."""
    print(f"üèÉ Running: {' '.join(cmd) if not shell else cmd} in {cwd}")
    try:
        result = subprocess.run(cmd, cwd=str(cwd), capture_output=capture, text=True, check=check, shell=shell)
        return result
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Command failed: {' '.join(cmd) if not shell else cmd}", file=sys.stderr)
        sys.exit(1)

def validate_git_remotes():
    """Validate git remote configuration and provide helpful guidance."""
    print("üîç Validating git remote configuration...")
    
    try:
        # Check if we're in a git repository
        run_command(['git', 'rev-parse', '--git-dir'], capture=True)
        
        # Check if origin remote exists
        remotes_result = run_command(['git', 'remote', '-v'], capture=True)
        remotes_output = remotes_result.stdout.strip()
        
        if not remotes_output:
            print("‚ö†Ô∏è  Warning: No git remotes configured")
            print("üí° To add origin remote: git remote add origin <repository-url>")
            return False
        
        # Check for origin specifically
        if 'origin' not in remotes_output:
            print("‚ö†Ô∏è  Warning: No 'origin' remote found")
            print("üí° To add origin remote: git remote add origin <repository-url>")
            print(f"üìã Current remotes:\n{remotes_output}")
            return False
        
        # Check current branch
        branch_result = run_command(['git', 'branch', '--show-current'], capture=True)
        current_branch = branch_result.stdout.strip()
        
        if not current_branch:
            print("‚ö†Ô∏è  Warning: Unable to determine current branch")
            return False
        
        print(f"‚úÖ Git validation passed:")
        print(f"   üìç Current branch: {current_branch}")
        print(f"   üîó Remote 'origin' configured")
        
        # Check upstream status (informational only)
        upstream_result = run_command(['git', 'rev-parse', '--abbrev-ref', f'{current_branch}@{{upstream}}'], 
                                    capture=True, check=False)
        
        if upstream_result.returncode == 0:
            upstream_branch = upstream_result.stdout.strip()
            print(f"   ‚¨ÜÔ∏è  Upstream: {upstream_branch}")
        else:
            print(f"   üîó No upstream configured (will be set automatically during push)")
        
        return True
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Git validation failed: {e}")
        print("üí° Make sure you're in a git repository with proper remote configuration")
        return False

def get_current_version():
    """Gets the version from pipulate/__init__.py."""
    content = INIT_PY_PATH.read_text()
    match = re.search(r"__version__\s*=\s*[\"']([^\"']+)[\"']", content)
    if not match:
        raise RuntimeError("Could not find __version__ in __init__.py")
    return match.group(1)

def run_version_sync():
    """Runs the version synchronization script."""
    print("\nüîÑ Step 1: Synchronizing versions across all files...")
    version_sync_script = PIPULATE_ROOT / "helpers" / "release" / "version_sync.py"
    if not version_sync_script.exists():
        print("‚ùå version_sync.py not found, skipping version sync")
        return False
    
    try:
        run_command(["python", str(version_sync_script)])
        print("‚úÖ Version synchronization complete")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è  Version sync failed: {e}")
        return False

def run_ascii_art_sync():
    """Runs the ASCII art documentation synchronization and captures statistics."""
    print("\nüìö Step 2: Synchronizing ASCII art documentation...")
    ascii_sync_script = PIPULATE_ROOT / "helpers" / "release" / "sync_ascii_art.py"
    if not ascii_sync_script.exists():
        print("‚ùå sync_ascii_art.py not found, skipping documentation sync")
        return False, None
    
    try:
        result = run_command([".venv/bin/python", str(ascii_sync_script)], capture=True)
        output = result.stdout
        
        # Parse statistics from output
        stats = parse_ascii_art_stats(output)
        
        print("‚úÖ ASCII art documentation synchronization complete")
        return True, stats
    except Exception as e:
        print(f"‚ö†Ô∏è  Documentation sync failed: {e}")
        return False, None

def parse_ascii_art_stats(output):
    """Parse ASCII art synchronization statistics from output."""
    stats = {
        'files_updated': 0,
        'total_blocks_updated': 0,
        'ascii_blocks_found': 0,
        'used_blocks': 0,
        'unused_blocks': 0,
        'coverage_percentage': 0.0,
        'heuristic_candidates': 0,
        'quality_candidates': 0,
        'unknown_markers': 0,
        'markdown_files_scanned': 0
    }
    
    try:
        import re
        
        # Extract key statistics using regex patterns
        patterns = {
            'files_updated': r'üìä Files updated:\s*(\d+)',
            'total_blocks_updated': r'üîÑ Total blocks updated:\s*(\d+)',
            'ascii_blocks_found': r'‚úÖ Found (\d+) ASCII blocks in README\.md',
            'markdown_files_scanned': r'üîç Found (\d+) markdown files',
            'used_blocks': r'‚úÖ Used blocks:\s*(\d+)',
            'unused_blocks': r'üìù Unused blocks:\s*(\d+)',
            'coverage_percentage': r'Used blocks:\s*\d+ \((\d+\.?\d*)%\)',
            'heuristic_candidates': r'Found (\d+) potential ASCII art blocks in naked fenced code blocks',
            'quality_candidates': r'HIGH-QUALITY CANDIDATES \((\d+)\)',
            'unknown_markers': r'UNKNOWN MARKERS FOUND \((\d+)\)'
        }
        
        for key, pattern in patterns.items():
            match = re.search(pattern, output)
            if match:
                if key == 'coverage_percentage':
                    stats[key] = float(match.group(1))
                else:
                    stats[key] = int(match.group(1))
    
    except Exception as e:
        print(f"‚ö†Ô∏è  Failed to parse ASCII art statistics: {e}")
    
    return stats

def display_ascii_art_stats(stats):
    """Display ASCII art synchronization statistics in a beautiful rich table."""
    if not RICH_AVAILABLE or not stats:
        # Fallback to simple text display
        if stats:
            print("\nüìä ASCII ART SYNC STATISTICS:")
            print(f"   üìÑ Markdown files scanned: {stats['markdown_files_scanned']}")
            print(f"   üì¶ ASCII blocks found: {stats['ascii_blocks_found']}")
            print(f"   ‚úÖ Used blocks: {stats['used_blocks']}")
            print(f"   üìù Unused blocks: {stats['unused_blocks']}")
            print(f"   üìä Coverage: {stats['coverage_percentage']:.1f}%")
            print(f"   üîÑ Files updated: {stats['files_updated']}")
            print(f"   üéØ Blocks updated: {stats['total_blocks_updated']}")
        return
    
    console = Console()
    
    # Create ASCII art statistics table
    table = Table(
        title="üìö ASCII Art Sync Statistics",
        box=box.ROUNDED,
        title_style="bold blue",
        header_style="bold cyan",
        show_header=True,
        show_lines=True,
        expand=True
    )
    
    table.add_column("Metric", style="bold yellow", width=25)
    table.add_column("Value", style="white", width=15)
    table.add_column("Status", justify="center", width=15)
    
    # Add rows with appropriate status indicators
    coverage = stats['coverage_percentage']
    coverage_status = "üéØ Excellent" if coverage >= 80 else "‚ö° Good" if coverage >= 60 else "üìà Improving"
    coverage_color = "green" if coverage >= 80 else "yellow" if coverage >= 60 else "red"
    
    table.add_row(
        "üìÑ Markdown Files Scanned",
        str(stats['markdown_files_scanned']),
        "üîç Complete"
    )
    
    table.add_row(
        "üì¶ ASCII Blocks Available", 
        str(stats['ascii_blocks_found']),
        "üìö Ready"
    )
    
    table.add_row(
        "‚úÖ Blocks in Use",
        str(stats['used_blocks']),
        "üé® Active"
    )
    
    table.add_row(
        "üìù Unused Blocks",
        str(stats['unused_blocks']),
        "üí§ Dormant" if stats['unused_blocks'] > 0 else "‚ú® All Used"
    )
    
    table.add_row(
        "üìä Coverage Percentage",
        Text(f"{coverage:.1f}%", style=f"bold {coverage_color}"),
        coverage_status
    )
    
    if stats['files_updated'] > 0:
        table.add_row(
            "üîÑ Files Updated",
            str(stats['files_updated']),
            "‚úÖ Synced"
        )
        
        table.add_row(
            "üéØ Blocks Updated",
            str(stats['total_blocks_updated']),
            "üöÄ Fresh"
        )
    else:
        table.add_row(
            "üîÑ Files Updated",
            "0",
            "‚ú® Current"
        )
    
    # Add discovery statistics if present
    if stats['heuristic_candidates'] > 0:
        table.add_row(
            "üîç New Candidates Found",
            str(stats['heuristic_candidates']),
            "üåü Potential"
        )
        
        if stats['quality_candidates'] > 0:
            table.add_row(
                "‚≠ê Quality Candidates",
                str(stats['quality_candidates']),
                "üé® Promote"
            )
    
    if stats['unknown_markers'] > 0:
        table.add_row(
            "‚ùì Unknown Markers",
            str(stats['unknown_markers']),
            "‚ö†Ô∏è Review"
        )
    
    # Create a panel around the table
    panel = Panel(
        table,
        title="üìö Documentation Sync Results",
        title_align="center",
        border_style="bright_blue",
        padding=(1, 2)
    )
    
    console.print("\n")
    console.print(panel)

def sync_install_sh():
    """Copies install.sh to Pipulate.com and commits if changed."""
    print("\nüîÑ Step 3: Synchronizing install.sh to Pipulate.com...")
    source_path = PIPULATE_ROOT / "install.sh"
    dest_path = PIPULATE_COM_ROOT / "install.sh"

    if not PIPULATE_COM_ROOT.exists():
        print(f"‚ö†Ô∏è  Warning: Pipulate.com repo not found at {PIPULATE_COM_ROOT}. Skipping install.sh sync.")
        return False

    if not source_path.exists():
        print(f"‚ö†Ô∏è  Warning: Source install.sh not found at {source_path}. Skipping install.sh sync.")
        return False

    # Copy the file
    dest_path.write_text(source_path.read_text())
    print(f"üìÑ Copied {source_path.name} to {dest_path}")

    # Check if there are changes in the Pipulate.com repo
    try:
        status_result = run_command(['git', 'status', '--porcelain', str(dest_path.name)], cwd=PIPULATE_COM_ROOT, capture=True)
        if status_result.stdout.strip():
            print(f"üì¶ Changes detected in {dest_path.name}. Committing and pushing...")
            run_command(['git', 'add', str(dest_path.name)], cwd=PIPULATE_COM_ROOT)
            commit_msg = f"chore: Update install.sh from pipulate repo v{get_current_version()}"
            run_command(['git', 'commit', '-m', commit_msg], cwd=PIPULATE_COM_ROOT)
            
            # Handle upstream branch setup for Pipulate.com repo
            try:
                # Try to get current branch name
                branch_result = run_command(['git', 'branch', '--show-current'], cwd=PIPULATE_COM_ROOT, capture=True)
                current_branch = branch_result.stdout.strip()
                
                # Check if upstream is configured
                upstream_result = run_command(['git', 'rev-parse', '--abbrev-ref', f'{current_branch}@{{upstream}}'], 
                                            cwd=PIPULATE_COM_ROOT, capture=True, check=False)
                
                if upstream_result.returncode != 0:
                    # No upstream configured, set it during push
                    print(f"üîó No upstream configured for Pipulate.com branch '{current_branch}', setting upstream...")
                    run_command(['git', 'push', '--set-upstream', 'origin', current_branch], cwd=PIPULATE_COM_ROOT)
                    print(f"‚úÖ Pushed install.sh update and set upstream: origin/{current_branch}")
                else:
                    # Upstream exists, normal push
                    run_command(['git', 'push'], cwd=PIPULATE_COM_ROOT)
                    print("‚úÖ Pushed install.sh update to Pipulate.com repo.")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è  Git push to Pipulate.com encountered an issue: {e}")
                print("üîÑ Attempting fallback push with upstream setup...")
                try:
                    # Fallback: try to push with upstream setup
                    branch_result = run_command(['git', 'branch', '--show-current'], cwd=PIPULATE_COM_ROOT, capture=True)
                    current_branch = branch_result.stdout.strip()
                    run_command(['git', 'push', '--set-upstream', 'origin', current_branch], cwd=PIPULATE_COM_ROOT)
                    print(f"‚úÖ Fallback successful: Pushed install.sh update and set upstream: origin/{current_branch}")
                except Exception as fallback_error:
                    print(f"‚ùå Fallback push to Pipulate.com also failed: {fallback_error}")
                    print("üí° Pipulate.com repo may need manual git remote configuration")
                    return False
            
            return True
        else:
            print("‚úÖ install.sh is already up-to-date in Pipulate.com repo.")
            return False
    except Exception as e:
        print(f"‚ö†Ô∏è  Install.sh sync failed: {e}")
        return False

def sync_breadcrumb_trail():
    """Syncs BREADCRUMB_TRAIL_DVCS.mdc to workspace root as DONT_WRITE_HERE.mdc with Cursor frontmatter."""
    print("\nüçû Step 4: Synchronizing breadcrumb trail to workspace root...")
    
    # Define paths
    source_path = PIPULATE_ROOT / ".cursor" / "rules" / "BREADCRUMB_TRAIL_DVCS.mdc"
    workspace_root = PIPULATE_ROOT.parent
    dest_path = workspace_root / ".cursor" / "rules" / "BREADCRUMB_TRAIL.mdc"
    
    if not source_path.exists():
        print(f"‚ö†Ô∏è  Warning: Source breadcrumb trail not found at {source_path}. Skipping breadcrumb sync.")
        return False
    
    # Create destination directory if it doesn't exist
    dest_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Read source content
    source_content = source_path.read_text()
    
    # Create destination content with Cursor frontmatter
    cursor_frontmatter = """---
description: 
globs: 
alwaysApply: true
---
"""
    
    dest_content = cursor_frontmatter + source_content
    
    # Check if content has changed
    content_changed = True
    if dest_path.exists():
        current_content = dest_path.read_text()
        content_changed = current_content != dest_content
    
    if content_changed:
        # Write the new content
        dest_path.write_text(dest_content)
        print(f"üìÑ Synced breadcrumb trail: {source_path.name} ‚Üí {dest_path}")
        print(f"üìç Location: {dest_path}")
        print("‚úÖ Breadcrumb trail updated at workspace root for Cursor 'Always include'.")
        return True
    else:
        print("‚úÖ Breadcrumb trail is already up-to-date at workspace root.")
        return False

def detect_trifecta_changes():
    """Check if the Botify Trifecta template has been modified in git."""
    trifecta_file = "plugins/400_botify_trifecta.py"
    
    try:
        # Check if file is in staged changes
        staged_result = run_command(['git', 'diff', '--staged', '--name-only'], capture=True)
        if trifecta_file in staged_result.stdout:
            return True, "staged"
        
        # Check if file is in unstaged changes
        unstaged_result = run_command(['git', 'diff', '--name-only'], capture=True)
        if trifecta_file in unstaged_result.stdout:
            return True, "unstaged"
        
        # Check if file was modified in the last commit (in case we're doing a force republish)
        last_commit_result = run_command(['git', 'diff', 'HEAD~1', 'HEAD', '--name-only'], capture=True)
        if trifecta_file in last_commit_result.stdout:
            return True, "last_commit"
        
        return False, None
    except Exception as e:
        print(f"‚ö†Ô∏è  Warning: Could not check Trifecta changes: {e}")
        return False, None

def rebuild_trifecta_derivatives():
    """Rebuild Parameter Buster and Link Graph from the updated Trifecta template."""
    print("\nüèóÔ∏è Step 4.5: Rebuilding Trifecta derivative plugins...")
    
    rebuild_script = PIPULATE_ROOT / "rebuild_trifecta_derivatives.sh"
    if not rebuild_script.exists():
        print(f"‚ö†Ô∏è  Warning: Trifecta rebuild script not found at {rebuild_script}. Skipping rebuild.")
        return False, {}
    
    try:
        print("üî® Executing deterministic Trifecta derivative reconstruction...")
        print("   üìç This ensures Parameter Buster and Link Graph inherit template improvements")
        
        # Run the rebuild script
        result = run_command([str(rebuild_script), "--verbose"], capture=True)
        output = result.stdout
        
        # Parse rebuild statistics from output
        stats = parse_trifecta_rebuild_stats(output)
        
        print("‚úÖ Trifecta derivative reconstruction complete")
        return True, stats
    except Exception as e:
        print(f"‚ö†Ô∏è  Trifecta rebuild failed: {e}")
        return False, {}

def parse_trifecta_rebuild_stats(output):
    """Parse Trifecta rebuild statistics from output."""
    stats = {
        'plugins_rebuilt': 0,
        'parameter_buster_methods': 0,
        'link_graph_methods': 0,
        'success_rate': 0,
        'validation_passed': False
    }
    
    try:
        import re
        
        # Extract statistics
        if "Successfully processed: 2/2 plugins" in output:
            stats['plugins_rebuilt'] = 2
            stats['success_rate'] = 100
            stats['validation_passed'] = True
        elif "Successfully processed: 1/2 plugins" in output:
            stats['plugins_rebuilt'] = 1
            stats['success_rate'] = 50
        
        # Extract method counts
        param_match = re.search(r'Found (\d+) workflow-specific methods.*parameter', output, re.IGNORECASE)
        if param_match:
            stats['parameter_buster_methods'] = int(param_match.group(1))
        
        link_match = re.search(r'Found (\d+) workflow-specific methods.*link', output, re.IGNORECASE)
        if link_match:
            stats['link_graph_methods'] = int(link_match.group(1))
        
        # Look for validation results
        if "Validation passed" in output:
            stats['validation_passed'] = True
    
    except Exception as e:
        print(f"‚ö†Ô∏è  Failed to parse Trifecta rebuild statistics: {e}")
    
    return stats

def display_trifecta_rebuild_stats(stats):
    """Display Trifecta rebuild statistics in a beautiful rich table."""
    if not RICH_AVAILABLE or not stats:
        # Fallback to simple text display
        if stats:
            print("\nüèóÔ∏è TRIFECTA REBUILD STATISTICS:")
            print(f"   üî® Plugins rebuilt: {stats['plugins_rebuilt']}/2")
            print(f"   üì¶ Parameter Buster methods: {stats['parameter_buster_methods']}")
            print(f"   üåê Link Graph methods: {stats['link_graph_methods']}")
            print(f"   ‚úÖ Success rate: {stats['success_rate']}%")
            print(f"   üéØ Validation: {'Passed' if stats['validation_passed'] else 'Failed'}")
        return
    
    console = Console()
    
    # Create Trifecta rebuild statistics table
    table = Table(
        title="üèóÔ∏è Trifecta Derivative Rebuild Statistics",
        box=box.ROUNDED,
        title_style="bold blue",
        header_style="bold cyan",
        show_header=True,
        show_lines=True,
        expand=True
    )
    
    table.add_column("Component", style="bold yellow", width=25)
    table.add_column("Value", style="white", width=15)
    table.add_column("Status", justify="center", width=15)
    
    # Add rebuild status
    success_color = "green" if stats['success_rate'] == 100 else "yellow" if stats['success_rate'] > 0 else "red"
    success_status = "üéØ Perfect" if stats['success_rate'] == 100 else "‚ö†Ô∏è Partial" if stats['success_rate'] > 0 else "‚ùå Failed"
    
    table.add_row(
        "üî® Plugins Rebuilt",
        f"{stats['plugins_rebuilt']}/2",
        Text(f"{stats['success_rate']}%", style=f"bold {success_color}")
    )
    
    if stats['parameter_buster_methods'] > 0:
        table.add_row(
            "üì¶ Parameter Buster Methods",
            str(stats['parameter_buster_methods']),
            "üî® Transplanted"
        )
    
    if stats['link_graph_methods'] > 0:
        table.add_row(
            "üåê Link Graph Methods", 
            str(stats['link_graph_methods']),
            "üî® Transplanted"
        )
    
    table.add_row(
        "üéØ Template Inheritance",
        "AST-based",
        "‚úÖ Deterministic" if stats['validation_passed'] else "‚ö†Ô∏è Check Required"
    )
    
    table.add_row(
        "üîç Validation Status",
        "Complete" if stats['validation_passed'] else "Failed",
        "‚úÖ Passed" if stats['validation_passed'] else "‚ùå Failed"
    )
    
    # Create a panel around the table
    panel = Panel(
        table,
        title="üèóÔ∏è Template Inheritance Results",
        title_align="center",
        border_style="bright_blue",
        padding=(1, 2)
    )
    
    console.print("\n")
    console.print(panel)

def get_ai_model_name():
    """Extract the model name from ai_commit.py."""
    ai_commit_script = PIPULATE_ROOT / "helpers" / "release" / "ai_commit.py"
    if not ai_commit_script.exists():
        return "AI Model"
    
    try:
        content = ai_commit_script.read_text()
        # Look for OLLAMA_MODEL = "model_name"
        import re
        match = re.search(r'OLLAMA_MODEL\s*=\s*["\']([^"\']+)["\']', content)
        if match:
            return match.group(1)
        else:
            return "AI Model"
    except Exception:
        return "AI Model"

def analyze_git_changes():
    """Intelligently analyze git changes to categorize additions, deletions, modifications, etc."""
    print("üîç Analyzing git changes for intelligent commit generation...")
    
    analysis = {
        'added_files': [],
        'deleted_files': [],
        'modified_files': [],
        'renamed_files': [],
        'lines_added': 0,
        'lines_deleted': 0,
        'is_housekeeping': False,
        'change_summary': '',
        'primary_action': 'modified'  # added, deleted, modified, renamed, housekeeping
    }
    
    try:
        # Get file status changes
        status_result = run_command(['git', 'status', '--porcelain'], capture=True)
        status_lines = status_result.stdout.strip().split('\n') if status_result.stdout.strip() else []
        
        for line in status_lines:
            if len(line) < 3:
                continue
            status = line[:2]
            filename = line[3:].strip()  # Remove any extra whitespace
            
            if status.startswith('A'):
                analysis['added_files'].append(filename)
            elif status.startswith('D'):
                analysis['deleted_files'].append(filename)
            elif status.startswith('M'):
                analysis['modified_files'].append(filename)
            elif status.startswith('R'):
                analysis['renamed_files'].append(filename)
        
        # Get line-level statistics using git diff --stat
        diff_stat_result = run_command(['git', 'diff', '--stat'], capture=True)
        if not diff_stat_result.stdout.strip():
            # Try staged changes
            diff_stat_result = run_command(['git', 'diff', '--staged', '--stat'], capture=True)
        
        stat_output = diff_stat_result.stdout.strip()
        if stat_output:
            # Parse the summary line (e.g., "3 files changed, 45 insertions(+), 12 deletions(-)")
            import re
            insertions_match = re.search(r'(\d+) insertions?\(\+\)', stat_output)
            deletions_match = re.search(r'(\d+) deletions?\(\-\)', stat_output)
            
            if insertions_match:
                analysis['lines_added'] = int(insertions_match.group(1))
            if deletions_match:
                analysis['lines_deleted'] = int(deletions_match.group(1))
        
        # Determine primary action and housekeeping nature
        total_files = len(analysis['added_files']) + len(analysis['deleted_files']) + len(analysis['modified_files']) + len(analysis['renamed_files'])
        
        # Check for housekeeping patterns
        housekeeping_indicators = [
            # File patterns that suggest cleanup
            any('test' in f.lower() for f in analysis['deleted_files']),
            any('.log' in f or '.tmp' in f or '.cache' in f for f in analysis['deleted_files']),
            any('backup' in f.lower() for f in analysis['deleted_files']),
            # High deletion-to-addition ratio
            analysis['lines_deleted'] > analysis['lines_added'] * 2 and analysis['lines_deleted'] > 50,
            # Mostly deletions with few/no additions
            len(analysis['deleted_files']) > len(analysis['added_files']) * 2 and len(analysis['deleted_files']) > 3
        ]
        
        analysis['is_housekeeping'] = any(housekeeping_indicators)
        
        # Determine primary action
        if len(analysis['deleted_files']) > len(analysis['added_files']) and len(analysis['deleted_files']) > len(analysis['modified_files']):
            analysis['primary_action'] = 'deleted'
        elif len(analysis['added_files']) > len(analysis['deleted_files']) and len(analysis['added_files']) > len(analysis['modified_files']):
            analysis['primary_action'] = 'added'
        elif len(analysis['renamed_files']) > 0:
            analysis['primary_action'] = 'renamed'
        elif analysis['is_housekeeping']:
            analysis['primary_action'] = 'housekeeping'
        else:
            analysis['primary_action'] = 'modified'
        
        # Create change summary
        parts = []
        if analysis['added_files']:
            parts.append(f"{len(analysis['added_files'])} files added")
        if analysis['deleted_files']:
            parts.append(f"{len(analysis['deleted_files'])} files deleted")
        if analysis['modified_files']:
            parts.append(f"{len(analysis['modified_files'])} files modified")
        if analysis['renamed_files']:
            parts.append(f"{len(analysis['renamed_files'])} files renamed")
        
        line_parts = []
        if analysis['lines_added']:
            line_parts.append(f"+{analysis['lines_added']} lines")
        if analysis['lines_deleted']:
            line_parts.append(f"-{analysis['lines_deleted']} lines")
        
        analysis['change_summary'] = ', '.join(parts)
        if line_parts:
            analysis['change_summary'] += f" ({', '.join(line_parts)})"
        
        print(f"üìä Change analysis: {analysis['change_summary']}")
        if analysis['is_housekeeping']:
            print("üßπ Detected housekeeping/cleanup operations")
        print(f"üéØ Primary action: {analysis['primary_action']}")
        
        return analysis
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Error analyzing git changes: {e}")
        return analysis

def get_ai_commit_message():
    """Gets an AI-generated commit message from local LLM with intelligent change analysis."""
    print("ü§ñ Analyzing changes for AI commit message...")
    
    # Check if there are any changes (staged or unstaged)
    try:
        staged_result = run_command(['git', 'diff', '--staged'], capture=True)
        unstaged_result = run_command(['git', 'diff'], capture=True)
        if not staged_result.stdout.strip() and not unstaged_result.stdout.strip():
            print("‚ùå No changes found for AI commit message generation")
            return None, None
    except Exception as e:
        print(f"‚ùå Error checking git changes: {e}")
        return None, None
    
    # Analyze changes intelligently
    change_analysis = analyze_git_changes()
    
    # Get the model name
    model_name = get_ai_model_name()
    
    # Try to get AI commit message with enhanced context
    ai_commit_script = PIPULATE_ROOT / "helpers" / "release" / "ai_commit.py"
    if not ai_commit_script.exists():
        print("‚ùå ai_commit.py not found, skipping AI commit generation")
        return None, None
    
    try:
        # Create enhanced environment variables to pass analysis to ai_commit.py
        import os
        import json
        
        # Pass the analysis as environment variable
        enhanced_env = os.environ.copy()
        enhanced_env['PIPULATE_CHANGE_ANALYSIS'] = json.dumps(change_analysis)
        
        # Use subprocess directly to pass environment variables
        import subprocess
        result = subprocess.run(
            ["python", str(ai_commit_script)], 
            cwd=str(PIPULATE_ROOT),
            capture_output=True,
            text=True,
            env=enhanced_env,
            check=False  # Don't raise exception on error
        )
        
        if result.returncode == 0:
            ai_message = result.stdout.strip()
            if ai_message:
                print(f"ü§ñ AI generated commit message:")
                print(f"   {ai_message}")
                return ai_message, model_name
            else:
                print("‚ö†Ô∏è  AI commit script returned empty message")
                return None, None
        else:
            print(f"‚ö†Ô∏è  AI commit script failed with error: {result.stderr}")
            return None, None
    except Exception as e:
        print(f"‚ö†Ô∏è  AI commit generation failed: {e}")
        print("üí° Make sure Ollama is running: ollama serve")
        return None, None

def display_beautiful_summary(commit_message, ai_generated=False, version=None, published=False, ai_model_name=None, trifecta_rebuilt=False, trifecta_stats=None):
    """Display a beautiful rich table summary of the release."""
    if not RICH_AVAILABLE:
        # Fallback to simple text display
        print("\n" + "="*60)
        print("üéâ RELEASE SUMMARY")
        print("="*60)
        if ai_generated:
            model_display = f" ({ai_model_name})" if ai_model_name else ""
            print(f"ü§ñ AI-Generated Commit Message{model_display}:")
            print(f"   {commit_message}")
        else:
            print(f"üìù Commit Message: {commit_message}")
        if version:
            print(f"üì¶ Version: {version}")
        if published:
            print(f"üöÄ Published to PyPI: ‚úÖ")
        if trifecta_rebuilt and trifecta_stats:
            print(f"üèóÔ∏è Trifecta Derivatives Rebuilt: {trifecta_stats.get('plugins_rebuilt', 0)}/2 plugins")
        print("="*60)
        return
    
    console = Console()
    
    # Create the main summary table
    table = Table(
        title="üéâ Pipulate Release Summary",
        box=box.ROUNDED,
        title_style="bold magenta",
        header_style="bold cyan",
        show_header=True,
        show_lines=True,
        expand=True
    )
    
    table.add_column("Component", style="bold yellow", width=20)
    table.add_column("Details", style="white", width=60)
    table.add_column("Status", justify="center", width=10)
    
    # Add commit message row with special styling for AI-generated
    if ai_generated:
        commit_text = Text(commit_message, style="italic green")
        ai_label = f"ü§ñ {ai_model_name} Message" if ai_model_name else "ü§ñ AI Commit Message"
        ai_status = f"‚ú® {ai_model_name}" if ai_model_name else "‚ú® AI"
        table.add_row(
            ai_label,
            commit_text,
            ai_status
        )
    else:
        table.add_row(
            "üìù Commit Message", 
            commit_message,
            "üìù Manual"
        )
    
    # Add version row if provided
    if version:
        table.add_row(
            "üì¶ Version",
            version,
            "‚úÖ Set"
        )
    
    # Add PyPI status if published
    if published:
        table.add_row(
            "üöÄ PyPI Release",
            f"https://pypi.org/project/pipulate/{version}/",
            "‚úÖ Live"
        )
    
    # Add Trifecta rebuild status if performed
    if trifecta_rebuilt and trifecta_stats:
        rebuild_status = "‚úÖ Perfect" if trifecta_stats.get('success_rate', 0) == 100 else "‚ö†Ô∏è Partial"
        table.add_row(
            "üèóÔ∏è Trifecta Derivatives",
            f"{trifecta_stats.get('plugins_rebuilt', 0)}/2 plugins",
            rebuild_status
        )
    
    # Add timestamp
    from datetime import datetime
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    table.add_row(
        "‚è∞ Completed",
        timestamp,
        "üéØ Done"
    )
    
    # Create a panel around the table for extra beauty
    panel = Panel(
        table,
        title="üéâ Release Pipeline Complete",
        title_align="center",
        border_style="bright_green",
        padding=(1, 2)
    )
    
    console.print("\n")
    console.print(panel)

def main():
    parser = argparse.ArgumentParser(description="Pipulate Master Release Orchestrator")
    parser.add_argument("--release", action="store_true", help="Perform a PyPI release")
    parser.add_argument("-m", "--message", type=str, help="Custom commit message")
    parser.add_argument("--force", action="store_true", help="Force operation even when no git changes detected")
    parser.add_argument("--ai-commit", action="store_true", help="Use AI to generate commit message")
    parser.add_argument("--skip-version-sync", action="store_true", help="Skip version synchronization")
    parser.add_argument("--skip-docs-sync", action="store_true", help="Skip documentation synchronization")
    parser.add_argument("--skip-install-sh-sync", action="store_true", help="Skip install.sh synchronization")
    parser.add_argument("--skip-breadcrumb-sync", action="store_true", help="Skip breadcrumb trail synchronization")
    parser.add_argument("--skip-trifecta-rebuild", action="store_true", help="Skip Trifecta derivative plugin rebuilding")
    
    args = parser.parse_args()
    
    print("üöÄ Pipulate Master Release Orchestrator")
    print("=" * 50)
    
    current_version = get_current_version()
    print(f"üìã Current version: {current_version}")
    
    # Early validation of git configuration
    if not validate_git_remotes():
        print("\n‚ùå Git remote validation failed. Please fix git configuration before proceeding.")
        sys.exit(1)
    
    # === RELEASE PIPELINE PHASE 1: PREPARATION ===
    print("\nüîß === RELEASE PIPELINE: PREPARATION PHASE ===")
    
    # Step 1: Version Synchronization
    if not args.skip_version_sync:
        version_sync_success = run_version_sync()
    else:
        print("\n‚è≠Ô∏è  Skipping version synchronization (--skip-version-sync)")
        version_sync_success = True
    
    # Step 2: Documentation Synchronization  
    if not args.skip_docs_sync:
        docs_sync_success, ascii_art_stats = run_ascii_art_sync()
        if ascii_art_stats:
            display_ascii_art_stats(ascii_art_stats)
    else:
        print("\n‚è≠Ô∏è  Skipping documentation synchronization (--skip-docs-sync)")
        docs_sync_success = True
        ascii_art_stats = None
    
    # Step 3: Install.sh Synchronization
    if not args.skip_install_sh_sync:
        install_sh_success = sync_install_sh()
    else:
        print("\n‚è≠Ô∏è  Skipping install.sh synchronization (--skip-install-sh-sync)")
        install_sh_success = False
    
    # Step 4: Breadcrumb Trail Synchronization
    if not args.skip_breadcrumb_sync:
        breadcrumb_sync_success = sync_breadcrumb_trail()
    else:
        print("\n‚è≠Ô∏è  Skipping breadcrumb trail synchronization (--skip-breadcrumb-sync)")
        breadcrumb_sync_success = False
    
    # Step 4.5: Trifecta Derivative Rebuilding (if template was modified)
    trifecta_rebuild_success = False
    trifecta_rebuild_stats = {}
    if not args.skip_trifecta_rebuild:
        trifecta_changed, change_type = detect_trifecta_changes()
        if trifecta_changed:
            print(f"\nüîç Detected Trifecta template changes ({change_type})")
            trifecta_rebuild_success, trifecta_rebuild_stats = rebuild_trifecta_derivatives()
            if trifecta_rebuild_stats:
                display_trifecta_rebuild_stats(trifecta_rebuild_stats)
        else:
            print("\n‚úÖ No Trifecta template changes detected - skipping derivative rebuild")
    else:
        print("\n‚è≠Ô∏è  Skipping Trifecta derivative rebuilding (--skip-trifecta-rebuild)")
    
    # === RELEASE PIPELINE PHASE 2: GIT OPERATIONS ===
    print("\nüìù === RELEASE PIPELINE: GIT OPERATIONS PHASE ===")
    
    # Check for git changes unless forcing
    has_changes = run_command(['git', 'status', '--porcelain'], capture=True).stdout.strip()
    
    if not has_changes and not args.force:
        print("\n‚úÖ No changes to commit. Your repository is clean.")
        if args.release:
            print("üí° Use --force to proceed with PyPI republishing anyway.")
        else:
            print("üí° Use --force to proceed anyway, or make some changes first.")
        sys.exit(0)
    elif not has_changes and args.force:
        print("\nüö® --force flag detected: Proceeding despite no git changes.")
        commit_message = args.message or "force: Manual republish without code changes"
        ai_generated_commit = False
        ai_model_name = None
    else:
        # We have changes, determine commit message
        if args.message:
            # User provided explicit message, use it
            commit_message = args.message
            ai_generated_commit = False
            ai_model_name = None
        else:
            # Default behavior: Try AI commit, fallback to standard message
            print("\nü§ñ Generating AI commit message...")
            ai_message, model_name = get_ai_commit_message()
            if ai_message:
                commit_message = ai_message
                ai_generated_commit = True
                ai_model_name = model_name
            else:
                print("‚ö†Ô∏è  Falling back to standard commit message")
                commit_message = "chore: Update project files"
                ai_generated_commit = False
                ai_model_name = None
    
    # Handle git operations
    if has_changes:
        print(f"\nüìù Commit message: {commit_message}")
        run_command(['git', 'commit', '-am', commit_message])
        
        # Check if upstream branch exists and push accordingly
        try:
            # Try to get current branch name
            branch_result = run_command(['git', 'branch', '--show-current'], capture=True)
            current_branch = branch_result.stdout.strip()
            
            # Check if upstream is configured
            upstream_result = run_command(['git', 'rev-parse', '--abbrev-ref', f'{current_branch}@{{upstream}}'], 
                                        capture=True, check=False)
            
            if upstream_result.returncode != 0:
                # No upstream configured, set it during push
                print(f"üîó No upstream configured for branch '{current_branch}', setting upstream...")
                run_command(['git', 'push', '--set-upstream', 'origin', current_branch])
                print(f"‚úÖ Pushed changes and set upstream: origin/{current_branch}")
            else:
                # Upstream exists, normal push
                run_command(['git', 'push'])
                print("‚úÖ Pushed changes to remote repository.")
                
        except Exception as e:
            print(f"‚ö†Ô∏è  Git push operation encountered an issue: {e}")
            print("üîÑ Attempting fallback push with upstream setup...")
            try:
                # Fallback: try to push with upstream setup
                branch_result = run_command(['git', 'branch', '--show-current'], capture=True)
                current_branch = branch_result.stdout.strip()
                run_command(['git', 'push', '--set-upstream', 'origin', current_branch])
                print(f"‚úÖ Fallback successful: Pushed changes and set upstream: origin/{current_branch}")
            except Exception as fallback_error:
                print(f"‚ùå Fallback push also failed: {fallback_error}")
                print("üí° You may need to manually configure git remote or check network connectivity")
                sys.exit(1)
                
    elif args.force:
        print("üö® --force flag: Skipping git commit (no changes to commit)")
        print("‚û°Ô∏è  Proceeding directly to PyPI publishing...")
    
    # === RELEASE PIPELINE PHASE 3: PYPI PUBLISHING ===
    published_to_pypi = False
    if args.release:
        print("\nüì¶ === RELEASE PIPELINE: PYPI PUBLISHING PHASE ===")
        print(f"üèóÔ∏è  Building and Publishing version {current_version} to PyPI...")
        print("üßπ Cleaning old build artifacts...")
        run_command("rm -rf dist/ build/ *.egg-info", shell=True)
        print("üõ†Ô∏è Building package...")
        run_command([".venv/bin/python", '-m', 'build'])
        print("üì¶ Publishing to PyPI...")
        run_command([".venv/bin/python", '-m', 'twine', 'upload', 'dist/*'])
        print(f"\nüéâ Successfully published version {current_version} to PyPI! üéâ")
        print(f"üìç View at: https://pypi.org/project/pipulate/{current_version}/")
        published_to_pypi = True
    
    # === BEAUTIFUL SUMMARY DISPLAY ===
    print("\n" + "=" * 50)
    display_beautiful_summary(
        commit_message=commit_message,
        ai_generated=ai_generated_commit,
        version=current_version,
        published=published_to_pypi,
        ai_model_name=ai_model_name,
        trifecta_rebuilt=trifecta_rebuild_success,
        trifecta_stats=trifecta_rebuild_stats
    )
    
    # üîÑ Trigger server restart so user can immediately talk to Chip about the update
    print("\nüîÑ Triggering server restart for immediate Chip interaction...")
    server_py_path = PIPULATE_ROOT / "server.py"
    if server_py_path.exists():
        # Touch the server.py file to trigger watchdog restart
        server_py_path.touch()
        print("‚úÖ Server restart triggered - you can now chat with Chip about this update!")
    else:
        print("‚ö†Ô∏è  server.py not found, manual restart may be needed")

if __name__ == "__main__":
    main()
