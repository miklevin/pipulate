{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pipulate import pip\n",
    "import secretsauce\n",
    "import nest_asyncio\n",
    "import keys\n",
    "nest_asyncio.apply()\n",
    "\n",
    "job = \"gapalyzer-01\" # Give your session a unique name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Here are the Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "secrets"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "pip.api_key(job, key=keys.google)\n",
    "botify_token = keys.botify\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Here are your Foes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "url-list-input"
    ]
   },
   "source": [
    "https://nixos.org/    # Linux\n",
    "https://pypi.org/     # Python\n",
    "https://neovim.io/    # vim\n",
    "https://git-scm.com/  # git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Save all of These"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from pathlib import Path\n",
    "\n",
    "def get_competitors_from_notebook(notebook_filename=\"GAPalyzer.ipynb\"):\n",
    "    \"\"\"Parses this notebook to get the domain list from the 'url-list-input' cell.\"\"\"\n",
    "    try:\n",
    "        notebook_path = Path(notebook_filename)\n",
    "        with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "            nb = nbformat.read(f, as_version=4)\n",
    "        \n",
    "        for cell in nb.cells:\n",
    "            if \"url-list-input\" in cell.metadata.get(\"tags\", []):\n",
    "                domains_raw = cell.source\n",
    "                domains = [\n",
    "                    line.split('#')[0].strip() \n",
    "                    for line in domains_raw.splitlines() \n",
    "                    if line.strip() and not line.strip().startswith('#')\n",
    "                ]\n",
    "                return domains\n",
    "        print(\"‚ö†Ô∏è Warning: Could not find a cell tagged with 'url-list-input'.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading domains from notebook: {e}\")\n",
    "        return []\n",
    "\n",
    "# --- Main Logic ---\n",
    "print(\"üöÄ Generating SEMrush URLs for GAP analysis...\")\n",
    "\n",
    "domains = get_competitors_from_notebook()\n",
    "url_template = \"https://www.semrush.com/analytics/organic/positions/?db=us&q={domain}&searchType=domain\"\n",
    "\n",
    "if not domains:\n",
    "    print(\"üõë No domains found. Please add competitor domains to the 'url-list-input' cell and re-run.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Found {len(domains)} competitor domains. Click the links below to open each report:\")\n",
    "    print(\"-\" * 30)\n",
    "    for i, domain in enumerate(domains):\n",
    "        full_url = url_template.format(domain=domain)\n",
    "        print(f\"{i+1}. {domain}:\\n   {full_url}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Stack 'Em, Join 'Em & Tag 'Em! ü•ûüß†üìä\n",
    "#### 1. Stack 'Em (turns all downloads into 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import nbformat # Make sure this import is here\n",
    "\n",
    "def get_all_domains_from_notebook(notebook_filename=\"GAPalyzer.ipynb\"):\n",
    "    \"\"\"Parses this notebook to get the full domain list from the 'url-list-input' cell.\"\"\"\n",
    "    try:\n",
    "        notebook_path = Path(notebook_filename)\n",
    "        with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "            nb = nbformat.read(f, as_version=4)\n",
    "        \n",
    "        for cell in nb.cells:\n",
    "            if \"url-list-input\" in cell.metadata.get(\"tags\", []):\n",
    "                domains_raw = cell.source\n",
    "                domains = [\n",
    "                    line.split('#')[0].strip() \n",
    "                    for line in domains_raw.splitlines() \n",
    "                    if line.strip() and not line.strip().startswith('#')\n",
    "                ]\n",
    "                return domains\n",
    "        print(\"‚ö†Ô∏è Warning: Could not find a cell tagged with 'url-list-input'.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading domains from notebook: {e}\")\n",
    "        return []\n",
    "\n",
    "# --- Main Logic ---\n",
    "print(\"ü•û Stacking 'Em: Consolidating all SEMrush Excel files...\")\n",
    "\n",
    "# 1. Get all domains from the notebook cell\n",
    "all_domains = get_all_domains_from_notebook()\n",
    "\n",
    "if not all_domains:\n",
    "    print(\"üõë No domains found. Please add your client and competitor domains to the 'url-list-input' cell.\")\n",
    "else:\n",
    "    # 2. THE NEW CONVENTION: The first domain is always the client's domain.\n",
    "    your_domain = all_domains[0]\n",
    "    print(f\"‚úÖ Client domain identified as: {your_domain}\")\n",
    "    \n",
    "    downloads_dir = Path.home() / \"Downloads\"\n",
    "    all_excel_files = list(downloads_dir.glob(\"*.xlsx\"))\n",
    "    \n",
    "    list_of_dataframes = []\n",
    "    for file_path in all_excel_files:\n",
    "        try:\n",
    "            domain_name = file_path.name.split('-organic.Positions')[0]\n",
    "            # Only process files that are in our domain list\n",
    "            if domain_name in all_domains:\n",
    "                df = pd.read_excel(file_path)\n",
    "                df['domain'] = domain_name\n",
    "                list_of_dataframes.append(df)\n",
    "                print(f\"  -> ‚úÖ Loaded and tagged {file_path.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  -> ‚ö†Ô∏è Could not process file {file_path.name}: {e}\")\n",
    "\n",
    "    if list_of_dataframes:\n",
    "        combined_df = pd.concat(list_of_dataframes, ignore_index=True)\n",
    "        print(\"\\nüéâ Success! All relevant Excel files have been consolidated.\")\n",
    "        display(combined_df.head())\n",
    "    else:\n",
    "        print(\"ü§∑ No matching Excel files were found in the Downloads folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### 2. Join 'em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"üß© Joining 'Em: Pivoting data to map keywords against competitors...\")\n",
    "\n",
    "if 'combined_df' not in locals() or 'your_domain' not in locals():\n",
    "    print(\"‚ùå 'combined_df' or 'your_domain' not found. Please run the 'Stack \\'Em' cell first.\")\n",
    "else:\n",
    "    try:\n",
    "        pivot_data = combined_df[['Keyword', 'domain', 'Search Volume']]\n",
    "        pivoted_df = pivot_data.pivot_table(\n",
    "            index='Keyword', \n",
    "            columns='domain', \n",
    "            values='Search Volume',\n",
    "            aggfunc='first'\n",
    "        ).fillna(0)\n",
    "\n",
    "        # Reorder columns to put the client's domain first\n",
    "        if your_domain in pivoted_df.columns:\n",
    "            cols = [your_domain] + [col for col in pivoted_df if col != your_domain]\n",
    "            pivoted_df = pivoted_df[cols]\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Warning: Your specified domain '{your_domain}' was not found in the data.\")\n",
    "\n",
    "        print(\"\\nüéâ Success! Data has been pivoted into a competitive matrix.\")\n",
    "        display(pivoted_df.head())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå An error occurred during the pivot process: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"üè∑Ô∏è Tagging 'Em: Identifying and scoring content gaps...\")\n",
    "\n",
    "if 'pivoted_df' not in locals() or 'combined_df' not in locals() or 'your_domain' not in locals():\n",
    "    print(\"‚ùå Required DataFrames or 'your_domain' variable not found. Please run the previous cells first.\")\n",
    "else:\n",
    "    try:\n",
    "        # Merge Search Volume back into the pivoted table\n",
    "        search_volumes = combined_df[['Keyword', 'Search Volume']].drop_duplicates().set_index('Keyword')\n",
    "        analysis_df = pivoted_df.merge(search_volumes, left_index=True, right_index=True)\n",
    "        \n",
    "        # Identify competitor columns\n",
    "        competitor_cols = [col for col in pivoted_df.columns if col != your_domain]\n",
    "        \n",
    "        # Count competitor rankings\n",
    "        analysis_df['competitor_count'] = (analysis_df[competitor_cols] > 0).sum(axis=1)\n",
    "        \n",
    "        # Find the gaps where your domain ranks 0\n",
    "        gap_df = analysis_df[analysis_df[your_domain] == 0].copy()\n",
    "        \n",
    "        # Score the opportunity\n",
    "        gap_df['opportunity_score'] = gap_df['Search Volume'] * gap_df['competitor_count']\n",
    "        \n",
    "        # Sort by the highest opportunity score\n",
    "        gap_df_sorted = gap_df.sort_values(by='opportunity_score', ascending=False)\n",
    "        \n",
    "        print(\"\\nüéâ Success! Content gaps have been identified and scored.\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        print(\"Top 20 Content Opportunities:\")\n",
    "        display(gap_df_sorted.head(20))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå An error occurred during the 'Tag \\'Em' process: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Step 4: Export to a Beautifully Formatted Excel File üé®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Todo\n",
    "- Make it work with Excel or CSV files\n",
    "- Bring your own CSV (Botify, GSC, etc) for joined rows & PageRank and other signals\n",
    "- A way to take ad hoc metrics into account with opportunity scores\n",
    "- Botify API integration in place of bring your own CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
