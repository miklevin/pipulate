{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pipulate import pip\n",
    "import secretsauce\n",
    "import nest_asyncio\n",
    "import keys\n",
    "nest_asyncio.apply()\n",
    "\n",
    "job = \"gapalyzer-01\" # Give your session a unique name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Here are the Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "secrets"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "pip.api_key(job, key=keys.google)\n",
    "botify_token = keys.botify\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Here are your Foes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "url-list-input"
    ]
   },
   "source": [
    "https://nixos.org/    # Linux\n",
    "https://pypi.org/     # Python\n",
    "https://neovim.io/    # vim\n",
    "https://git-scm.com/  # git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Save all of These"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from pathlib import Path\n",
    "\n",
    "def get_competitors_from_notebook(notebook_filename=\"GAPalyzer.ipynb\"):\n",
    "    \"\"\"Parses this notebook to get the domain list from the 'url-list-input' cell.\"\"\"\n",
    "    try:\n",
    "        notebook_path = Path(notebook_filename)\n",
    "        with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "            nb = nbformat.read(f, as_version=4)\n",
    "        \n",
    "        for cell in nb.cells:\n",
    "            if \"url-list-input\" in cell.metadata.get(\"tags\", []):\n",
    "                domains_raw = cell.source\n",
    "                domains = [\n",
    "                    line.split('#')[0].strip() \n",
    "                    for line in domains_raw.splitlines() \n",
    "                    if line.strip() and not line.strip().startswith('#')\n",
    "                ]\n",
    "                return domains\n",
    "        print(\"‚ö†Ô∏è Warning: Could not find a cell tagged with 'url-list-input'.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading domains from notebook: {e}\")\n",
    "        return []\n",
    "\n",
    "# --- Main Logic ---\n",
    "print(\"üöÄ Generating SEMrush URLs for GAP analysis...\")\n",
    "\n",
    "domains = get_competitors_from_notebook()\n",
    "url_template = \"https://www.semrush.com/analytics/organic/positions/?db=us&q={domain}&searchType=domain\"\n",
    "\n",
    "if not domains:\n",
    "    print(\"üõë No domains found. Please add competitor domains to the 'url-list-input' cell and re-run.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Found {len(domains)} competitor domains. Click the links below to open each report:\")\n",
    "    print(\"-\" * 30)\n",
    "    for i, domain in enumerate(domains):\n",
    "        full_url = url_template.format(domain=domain)\n",
    "        print(f\"{i+1}. {domain}:\\n   {full_url}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Stack 'Em, Join 'Em & Tag 'Em! ü•ûüß†üìä\n",
    "#### 1. Stack 'Em (turns all downloads into 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import nbformat # Make sure this import is here\n",
    "\n",
    "def get_all_domains_from_notebook(notebook_filename=\"GAPalyzer.ipynb\"):\n",
    "    \"\"\"Parses this notebook to get the full domain list from the 'url-list-input' cell.\"\"\"\n",
    "    try:\n",
    "        notebook_path = Path(notebook_filename)\n",
    "        with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "            nb = nbformat.read(f, as_version=4)\n",
    "        \n",
    "        for cell in nb.cells:\n",
    "            if \"url-list-input\" in cell.metadata.get(\"tags\", []):\n",
    "                domains_raw = cell.source\n",
    "                domains = [\n",
    "                    line.split('#')[0].strip() \n",
    "                    for line in domains_raw.splitlines() \n",
    "                    if line.strip() and not line.strip().startswith('#')\n",
    "                ]\n",
    "                return domains\n",
    "        print(\"‚ö†Ô∏è Warning: Could not find a cell tagged with 'url-list-input'.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading domains from notebook: {e}\")\n",
    "        return []\n",
    "\n",
    "# --- Main Logic ---\n",
    "print(\"ü•û Stacking 'Em: Consolidating all SEMrush Excel files...\")\n",
    "\n",
    "# 1. Get all domains from the notebook cell\n",
    "all_domains = get_all_domains_from_notebook()\n",
    "\n",
    "if not all_domains:\n",
    "    print(\"üõë No domains found. Please add your client and competitor domains to the 'url-list-input' cell.\")\n",
    "else:\n",
    "    # 2. THE NEW CONVENTION: The first domain is always the client's domain.\n",
    "    your_domain = all_domains[0]\n",
    "    print(f\"‚úÖ Client domain identified as: {your_domain}\")\n",
    "    \n",
    "    downloads_dir = Path.home() / \"Downloads\"\n",
    "    all_excel_files = list(downloads_dir.glob(\"*.xlsx\"))\n",
    "    \n",
    "    list_of_dataframes = []\n",
    "    for file_path in all_excel_files:\n",
    "        try:\n",
    "            domain_name = file_path.name.split('-organic.Positions')[0]\n",
    "            # Only process files that are in our domain list\n",
    "            if domain_name in all_domains:\n",
    "                df = pd.read_excel(file_path)\n",
    "                df['domain'] = domain_name\n",
    "                list_of_dataframes.append(df)\n",
    "                print(f\"  -> ‚úÖ Loaded and tagged {file_path.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  -> ‚ö†Ô∏è Could not process file {file_path.name}: {e}\")\n",
    "\n",
    "    if list_of_dataframes:\n",
    "        combined_df = pd.concat(list_of_dataframes, ignore_index=True)\n",
    "        print(\"\\nüéâ Success! All relevant Excel files have been consolidated.\")\n",
    "        display(combined_df.head())\n",
    "    else:\n",
    "        print(\"ü§∑ No matching Excel files were found in the Downloads folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### 2. Join 'em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"üß© Joining 'Em: Pivoting data to map keywords against competitors...\")\n",
    "\n",
    "if 'combined_df' not in locals() or 'your_domain' not in locals():\n",
    "    print(\"‚ùå 'combined_df' or 'your_domain' not found. Please run the 'Stack \\'Em' cell first.\")\n",
    "else:\n",
    "    try:\n",
    "        pivot_data = combined_df[['Keyword', 'domain', 'Search Volume']]\n",
    "        pivoted_df = pivot_data.pivot_table(\n",
    "            index='Keyword', \n",
    "            columns='domain', \n",
    "            values='Search Volume',\n",
    "            aggfunc='first'\n",
    "        ).fillna(0)\n",
    "\n",
    "        # Reorder columns to put the client's domain first\n",
    "        if your_domain in pivoted_df.columns:\n",
    "            cols = [your_domain] + [col for col in pivoted_df if col != your_domain]\n",
    "            pivoted_df = pivoted_df[cols]\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Warning: Your specified domain '{your_domain}' was not found in the data.\")\n",
    "\n",
    "        print(\"\\nüéâ Success! Data has been pivoted into a competitive matrix.\")\n",
    "        display(pivoted_df.head())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå An error occurred during the pivot process: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"üè∑Ô∏è Tagging 'Em: Identifying and scoring content gaps...\")\n",
    "\n",
    "if 'pivoted_df' not in locals() or 'combined_df' not in locals() or 'your_domain' not in locals():\n",
    "    print(\"‚ùå Required DataFrames or 'your_domain' variable not found. Please run the previous cells first.\")\n",
    "else:\n",
    "    try:\n",
    "        # Merge Search Volume back into the pivoted table\n",
    "        search_volumes = combined_df[['Keyword', 'Search Volume']].drop_duplicates().set_index('Keyword')\n",
    "        analysis_df = pivoted_df.merge(search_volumes, left_index=True, right_index=True)\n",
    "        \n",
    "        # Identify competitor columns\n",
    "        competitor_cols = [col for col in pivoted_df.columns if col != your_domain]\n",
    "        \n",
    "        # Count competitor rankings\n",
    "        analysis_df['competitor_count'] = (analysis_df[competitor_cols] > 0).sum(axis=1)\n",
    "        \n",
    "        # Find the gaps where your domain ranks 0\n",
    "        gap_df = analysis_df[analysis_df[your_domain] == 0].copy()\n",
    "        \n",
    "        # Score the opportunity\n",
    "        gap_df['opportunity_score'] = gap_df['Search Volume'] * gap_df['competitor_count']\n",
    "        \n",
    "        # Sort by the highest opportunity score\n",
    "        gap_df_sorted = gap_df.sort_values(by='opportunity_score', ascending=False)\n",
    "        \n",
    "        print(\"\\nüéâ Success! Content gaps have been identified and scored.\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        print(\"Top 20 Content Opportunities:\")\n",
    "        display(gap_df_sorted.head(20))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå An error occurred during the 'Tag \\'Em' process: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Step 4: Export to a Beautifully Formatted Excel File üé®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import openpyxl\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import Font, Alignment\n",
    "from openpyxl.worksheet.table import Table, TableStyleInfo\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import platform\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def export_gap_analysis_to_excel(job: str, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Exports the GAPalyzer DataFrame to a professionally formatted Excel file\n",
    "    inside the 'output' folder.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"‚ö†Ô∏è DataFrame is empty, skipping file export.\")\n",
    "        return\n",
    "\n",
    "    output_dir = Path(\"output\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    excel_filename = output_dir / f\"{job}_gap_analysis.xlsx\"\n",
    "    \n",
    "    print(f\"üé® Formatting and exporting data to Excel: {excel_filename}\")\n",
    "    \n",
    "    with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n",
    "        df.to_excel(writer, index=False, sheet_name='GAP_Analysis')\n",
    "        \n",
    "        worksheet = writer.sheets['GAP_Analysis']\n",
    "\n",
    "        # 1. Create an Excel Table for banded rows and filtering\n",
    "        table_range = f\"A1:{get_column_letter(worksheet.max_column)}{worksheet.max_row}\"\n",
    "        table = Table(displayName=\"GapAnalysisTable\", ref=table_range)\n",
    "        style = TableStyleInfo(name=\"TableStyleMedium9\", showFirstColumn=False,\n",
    "                               showLastColumn=False, showRowStripes=True, showColumnStripes=False)\n",
    "        table.tableStyleInfo = style\n",
    "        worksheet.add_table(table)\n",
    "\n",
    "        # 2. Define consistent column widths\n",
    "        # We'll make educated guesses for the columns from your pivot\n",
    "        width_map = {\n",
    "            \"Keyword\": 50,\n",
    "            \"Search Volume\": 18,\n",
    "            \"competitor_count\": 18,\n",
    "            \"opportunity_score\": 18,\n",
    "        }\n",
    "        default_width = 15 # For competitor domains\n",
    "\n",
    "        # 3. Apply formatting\n",
    "        for col_idx, column_cell in enumerate(worksheet[1], 1):\n",
    "            column_letter = get_column_letter(col_idx)\n",
    "            header_text = str(column_cell.value)\n",
    "            \n",
    "            # A. Format header cell\n",
    "            column_cell.font = Font(bold=True)\n",
    "            column_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "\n",
    "            # B. Set column width\n",
    "            width = width_map.get(header_text, default_width)\n",
    "            worksheet.column_dimensions[column_letter].width = width\n",
    "\n",
    "        # 4. Apply text wrapping and vertical alignment to all data cells\n",
    "        for row in worksheet.iter_rows(min_row=2):\n",
    "            for cell in row:\n",
    "                cell.alignment = Alignment(wrap_text=True, vertical='top')\n",
    "\n",
    "    print(f\"‚úÖ Success! Files saved in the '{output_dir}' folder.\")\n",
    "    \n",
    "    # --- Helper to open the output folder ---\n",
    "    def _open_folder(path_str: str = \".\"):\n",
    "        folder_path = Path(path_str).resolve()\n",
    "        print(f\"Attempting to open folder: {folder_path}\")\n",
    "        if not folder_path.exists() or not folder_path.is_dir():\n",
    "            print(f\"‚ùå Error: Path is not a valid directory: {folder_path}\")\n",
    "            return\n",
    "        system = platform.system()\n",
    "        try:\n",
    "            if system == \"Windows\": os.startfile(folder_path)\n",
    "            elif system == \"Darwin\": subprocess.run([\"open\", folder_path])\n",
    "            else: subprocess.run([\"xdg-open\", folder_path])\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to open folder. Please navigate to it manually. Error: {e}\")\n",
    "\n",
    "    # --- Display the \"Open Folder\" button ---\n",
    "    button = widgets.Button(\n",
    "        description=\"üìÇ Open Output Folder\",\n",
    "        tooltip=f\"Open {output_dir.resolve()}\",\n",
    "        button_style='success'\n",
    "    )\n",
    "    button.on_click(lambda b: _open_folder(\"output\"))\n",
    "    display(button)\n",
    "\n",
    "# --- Main Logic ---\n",
    "if 'gap_df_sorted' not in locals():\n",
    "    print(\"‚ùå 'gap_df_sorted' not found. Please run the 'Tag \\'Em' cell first.\")\n",
    "else:\n",
    "    # Call the export function\n",
    "    export_gap_analysis_to_excel(job, gap_df_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Todo\n",
    "- Make it work with Excel or CSV files\n",
    "- Bring your own CSV (Botify, GSC, etc) for joined rows & PageRank and other signals\n",
    "- A way to take ad hoc metrics into account with opportunity scores\n",
    "- Botify API integration in place of bring your own CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
