---
description: 
globs: 
alwaysApply: false
---
# Data Patterns and Best Practices

## Data Structure

1. **State Data**
   ```python
   {
       "app_name": "widget_name",
       "step_01": {
           "data_field": "value",
           "metadata": {
               "timestamp": "2024-03-21T12:00:00",
               "version": "1.0"
           }
       }
   }
   ```

2. **File Data**
   ```python
   {
       "filename": "example.txt",
       "size": 1024,
       "path": "/path/to/file",
       "type": "text/plain",
       "metadata": {
           "uploaded_at": "2024-03-21T12:00:00",
           "checksum": "abc123"
       }
   }
   ```

3. **Table Data**
   ```python
   {
       "columns": ["col1", "col2"],
       "data": [
           {"col1": "value1", "col2": "value2"},
           {"col1": "value3", "col2": "value4"}
       ],
       "metadata": {
           "total_rows": 2,
           "page": 1
       }
   }
   ```

## Data Operations

1. **State Management**
   ```python
   # Initialize
   state, error = pip.initialize_if_missing(pipeline_id, initial_state)
   
   # Update
   await pip.update_step_state(pipeline_id, step_id, data, steps)
   
   # Read
   data = pip.get_step_data(pipeline_id, step_id, default={})
   
   # Clear
   await pip.clear_steps_from(pipeline_id, step_id, steps)
   ```

2. **File Operations**
   ```python
   # Save file
   with open(file_path, "wb") as f:
       f.write(contents)
   
   # Read file
   with open(file_path, "rb") as f:
       contents = f.read()
   
   # Delete file
   os.remove(file_path)
   ```

3. **Data Validation**
   ```python
   def validate_data(data):
       if not data:
           raise ValueError("Data is required")
       if not isinstance(data, dict):
           raise TypeError("Data must be a dictionary")
       return data
   ```

## Data Transformation

1. **Text Processing**
   ```python
   def transform_text(text):
       return text.strip() if text else ""
   ```

2. **File Processing**
   ```python
   def process_file(file):
       return {
           "name": file.filename,
           "size": len(file.read()),
           "type": file.content_type
       }
   ```

3. **Table Processing**
   ```python
   def process_table(data):
       return {
           "columns": data.columns.tolist(),
           "rows": data.to_dict("records")
       }
   ```

## Data Storage

1. **File Storage**
   ```python
   save_directory = Path("downloads") / app_name / pipeline_id
   save_directory.mkdir(parents=True, exist_ok=True)
   ```

2. **State Storage**
   ```python
   state = {
       "app_name": app_name,
       "timestamp": datetime.now().isoformat(),
       "data": data
   }
   ```

3. **Cache Storage**
   ```python
   cache = {
       "key": value,
       "expires": datetime.now() + timedelta(hours=1)
   }
   ```

## Data Security

1. **Input Validation**
   ```python
   def validate_input(data):
       if not isinstance(data, (str, bytes)):
           raise TypeError("Invalid input type")
       return data
   ```

2. **File Validation**
   ```python
   def validate_file(file):
       if not file.filename:
           raise ValueError("No file selected")
       if file.size > MAX_SIZE:
           raise ValueError("File too large")
       return file
   ```

3. **Path Security**
   ```python
   def secure_path(path):
       return Path(path).resolve().relative_to(Path.cwd())
   ```

## Data Recovery

1. **State Recovery**
   ```python
   def recover_state(pipeline_id):
       state = pip.read_state(pipeline_id)
       if not state:
           return initialize_state()
       return state
   ```

2. **File Recovery**
   ```python
   def recover_file(file_path):
       if not file_path.exists():
           return None
       return file_path.read_bytes()
   ```

3. **Data Backup**
   ```python
   def backup_data(data):
       backup_path = Path("backups") / f"{datetime.now():%Y%m%d_%H%M%S}.json"
       backup_path.write_text(json.dumps(data))
   ```

## Data Export

1. **JSON Export**
   ```python
   def export_json(data):
       return json.dumps(data, indent=2)
   ```

2. **CSV Export**
   ```python
   def export_csv(data):
       return pd.DataFrame(data).to_csv(index=False)
   ```

3. **File Export**
   ```python
   def export_file(data, path):
       path.write_bytes(data)
   ```

## Data Import

1. **JSON Import**
   ```python
   def import_json(data):
       return json.loads(data)
   ```

2. **CSV Import**
   ```python
   def import_csv(data):
       return pd.read_csv(StringIO(data))
   ```

3. **File Import**
   ```python
   def import_file(path):
       return path.read_bytes()
   ```

## Best Practices

1. **Data Validation**
   - Validate all inputs
   - Check data types
   - Verify data integrity

2. **Error Handling**
   - Handle missing data
   - Process errors gracefully
   - Provide clear messages

3. **Performance**
   - Use efficient data structures
   - Minimize data copying
   - Cache when appropriate

4. **Security**
   - Sanitize inputs
   - Validate file types
   - Secure file paths

5. **Maintenance**
   - Document data structures
   - Version data formats
   - Track data changes
